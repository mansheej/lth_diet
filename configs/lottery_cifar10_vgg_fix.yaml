seed: 6174
# model
model:
  vgg16:
    num_classes: 10
# data
train_data:
  cifar10:
    train: true
val_data:
  cifar10:
    train: false
# training:
train_batch_size: 128
val_batch_size: 1000
optimizer:
  sgd:
    lr: 0.1
    momentum: 0.9
    weight_decay: 0.0001
schedulers:
  multistep:
    milestones:
    - 31200ba
    - 46800ba
    gamma: 0.1
max_duration: 62400ba
algorithms:
  channels_last: {}
callbacks:
  lr_monitor: {}
# pruning
levels: 16
rewinding_steps: 200ba
pruning:
  pruning_layers_to_ignore: fc.weight
# pretraining
pretrain_data:
  cifar10:
    train: true
pretrain_optimizer:
  sgd:
    lr: 0.1
    momentum: 0.9
    weight_decay: 0.0001
# boilerplate
loggers:
  file:
    log_level: 3
  wandb:
    project: lth_diet
    entity: prunes
dataloader:
  persistent_workers: false
object_store:
  provider: google_storage
  container: prunes
  key_environ: GCS_KEY
