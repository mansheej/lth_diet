{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from composer.callbacks import LRMonitorHparams\n",
    "from composer.datasets import DataLoaderHparams\n",
    "from composer.loggers import WandBLoggerHparams\n",
    "from composer.models import ComposerClassifier\n",
    "from composer.optim import SGDHparams, CosineAnnealingSchedulerHparams, MultiStepSchedulerHparams, ConstantSchedulerHparams\n",
    "from composer.trainer import Trainer, TrainerHparams\n",
    "from composer.utils.object_store import ObjectStoreProviderHparams, ObjectStoreProvider\n",
    "from copy import deepcopy\n",
    "from lth_diet.data import CIFAR10DataHparams, DataHparams\n",
    "from lth_diet.exps import LotteryExperiment\n",
    "from lth_diet.models import ResNetCIFARClassifierHparams, ClassifierHparams\n",
    "from lth_diet.pruning import Mask, PrunedClassifier, PruningHparams\n",
    "from lth_diet.pruning.pruned_classifier import prunable_layer_names\n",
    "from lth_diet.utils import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "plt.style.use(\"default\")\n",
    "rc = {\"figure.figsize\": (4, 3), \"figure.dpi\": 150, \"figure.constrained_layout.use\": True, \"axes.grid\": True, \n",
    "      \"axes.spines.right\": False, \"axes.spines.top\": False, \"axes.linewidth\": 0.6, \"grid.linewidth\": 0.6,\n",
    "      \"xtick.major.width\": 0.6, \"ytick.major.width\": 0.6, \"xtick.major.size\": 4, \"ytick.major.size\": 4, \n",
    "      \"axes.labelsize\": 11, \"axes.titlesize\": 11, \"xtick.labelsize\": 10, \"ytick.labelsize\": 10,\n",
    "      \"axes.titlepad\": 4, \"axes.labelpad\": 2, \"xtick.major.pad\": 2, \"ytick.major.pad\": 2,\n",
    "      \"lines.linewidth\": 1.2, 'lines.markeredgecolor': 'w', \"patch.linewidth\": 0}\n",
    "sns.set_theme(style='ticks', palette=sns.color_palette(\"tab10\"), rc=rc)\n",
    "object_store = ObjectStoreProviderHparams('google_storage', 'prunes', 'GCS_KEY').initialize_object()\n",
    "bucket_dir = os.environ['OBJECT_STORE_DIR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with the LotteryExperiment in lottery_test but with rewinding step 2000 (this is where IMP works really well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lottery(model=ResNetCIFAR(num_classes=10,num_layers=20),train_data=CIFAR10(train=True),train_batch_size=128,optimizer=SGDHparams(lr=0.1,momentum=0.9,weight_decay=0.0001,dampening=0.0,nesterov=False),schedulers=[MultiStepSchedulerHparams(milestones=[31200ba,46800ba],gamma=0.1)],max_duration=62400ba,seed=6174,rewinding_steps=2000ba,pruning=PruningHparams(pruning_fraction=0.2),algorithms=[ChannelsLastHparams()],callbacks=[LRMonitorHparams()])\n"
     ]
    }
   ],
   "source": [
    "config = \"../configs/lottery_test.yaml\"\n",
    "exp = LotteryExperiment.create(config, cli_args=False)\n",
    "exp.rewinding_steps = \"2000ba\"\n",
    "print(exp.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the replicate 0 to start with. Initial model is a fully trained dense network, i.e. level 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "replicate = 1\n",
    "level = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the training and test data loaders. Prepare model_hparams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CIFAR10DataHparams(True).initialize_object(128, DataLoaderHparams(persistent_workers=False))\n",
    "test_data = CIFAR10DataHparams(False).initialize_object(1000, DataLoaderHparams(persistent_workers=False))\n",
    "# print(train_data.dataset, \"\\n\", train_data.batch_size, \"\\n\", test_data.dataset)\n",
    "model_hparams = ResNetCIFARClassifierHparams(10, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location of the model and the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6367fcd0a8f09134f8c65d472df6880e/replicate_0/level_0/main\n"
     ]
    }
   ],
   "source": [
    "exp_hash = utils.get_hash(exp.name)\n",
    "location = f\"{exp_hash}/replicate_{replicate}/level_{level}/main\"\n",
    "print(location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for loading state_dict and mask from the cloud and constructing a PrunedClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pruned_model_from_cloud(\n",
    "    exp: LotteryExperiment, replicate: int, level: int, model_hparams: ClassifierHparams, \n",
    "    object_store: ObjectStoreProvider, ckpt: str\n",
    ") -> PrunedClassifier:\n",
    "    exp_hash = utils.get_hash(exp.name)\n",
    "    location = f\"{exp_hash}/replicate_{replicate}/level_{level}/main\"\n",
    "    name = f\"model_{ckpt}.pt\"\n",
    "    state_dict = utils.load_object(location, name, object_store, torch.load)\n",
    "    model = model_hparams.initialize_object()\n",
    "    model.module.load_state_dict(state_dict)\n",
    "    mask = Mask.load(location, object_store)\n",
    "    pruned_model = PrunedClassifier(model, mask)\n",
    "    pruned_model.cpu()\n",
    "    pruned_model.eval()\n",
    "    return pruned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load level 0 final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model = load_pruned_model_from_cloud(exp, replicate, level, model_hparams, object_store, \"final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate the density of a PrunedClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pruned_model_density(model: PrunedClassifier) -> float:\n",
    "    names = [PrunedClassifier.to_mask_name(name) for name in prunable_layer_names(model)]\n",
    "    params = torch.cat([getattr(model, name).flatten() for name in names])\n",
    "    return (params != 0).float().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the density of the model is 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(get_pruned_model_density(pruned_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate accuracy of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model: ComposerClassifier, data: DataHparams) -> float:\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for batch in tqdm(data):\n",
    "        batch = batch[0].cuda(), batch[1].cuda()\n",
    "        logits = model(batch)\n",
    "        correct += (logits.argmax(dim=-1) == batch[1]).sum()\n",
    "    model.cpu()\n",
    "    return (correct / len(data.dataset)).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate test accuracy of our level 0 final model: 91.34%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9133999943733215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_accuracy(pruned_model, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the level 0 final PrunedClassifier as `model_0.pt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pruned_model.module.state_dict(), \"crazy/model_0.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to save the mask for this classifier. Note, the mask is a ones mask. Save it as `mask_0.pt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = Mask.ones_like(pruned_model)\n",
    "torch.save(mask, \"crazy/mask_0.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New mask: magnitude prune 20% of the current mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = PruningHparams(pruning_fraction=0.2).prune(pruned_model, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the mask density is 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80\n"
     ]
    }
   ],
   "source": [
    "print(f\"{mask.density.item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check: mask should be the same as level 1 of LotteryExperiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mask = Mask.load(f\"{exp_hash}/replicate_{replicate}/level_{1}/main\", object_store)\n",
    "for k, v in test_mask.items():\n",
    "    if not (v == mask[k]).all().item():\n",
    "        print(\"test failed\")\n",
    "        break\n",
    "del test_mask, k, v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save mask as `mask_1.pt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mask, \"crazy/mask_1.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear up the model and mask for safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pruned_model, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a pruned model from model name and mask name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pruned_model(model_name: str, mask_name: str, model_hparams: ClassifierHparams) -> PrunedClassifier:\n",
    "    state_dict = torch.load(f\"crazy/{model_name}.pt\")\n",
    "    model = model_hparams.initialize_object()\n",
    "    model.module.load_state_dict(state_dict)\n",
    "    mask = torch.load(f\"crazy/{mask_name}.pt\")\n",
    "    model.cpu()\n",
    "    model.eval()\n",
    "    return PrunedClassifier(model, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take `model_0` and project it with `mask_1` to get `model_1__0`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1__0 = load_pruned_model(\"model_0\", \"mask_1\", model_hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well does `model_1__0` perform (initial model after projection)? 91.27% ... not bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9126999974250793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_accuracy(model_1__0, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save `model_1__0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_1__0.module.state_dict(), \"crazy/model_1__0.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train `model1_1__1`. 5 epochs seems enough. Same hyperparameters as where we left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmansheej\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.13"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mansheej/lth_diet/ipynbs/wandb/run-20220505_060016-mk5419dj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/prunes/lth_diet/runs/mk5419dj\" target=\"_blank\">robust-butterfly</a></strong> to <a href=\"https://wandb.ai/prunes/lth_diet\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e9eda51ebe42a9b264a54d07a95b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy/val</td><td>▁▂▁▃▃▃▂▄▆█</td></tr><tr><td>crossentropyloss/val</td><td>▂▄▂▄▁▆▃▃█▂</td></tr><tr><td>epoch</td><td>▁▁▃▃▅▅▆▆███</td></tr><tr><td>loss/train</td><td>▄▂▄▁▂█▁▃▃▂▁▂▄▃▂▃▁█▃▃▂▃▆▃▂▃▃▃▄▁█▁▁▅▂▃▁▃▂▃</td></tr><tr><td>lr-SGD/group0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/batch_idx</td><td>▁▂▃▄▅▆▇█▁▂▃▄▅▆▇█▁▂▃▄▅▆▇█▁▂▃▄▅▆▇█▁▂▃▄▅▆▇█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy/val</td><td>0.9137</td></tr><tr><td>crossentropyloss/val</td><td>0.3595</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>loss/train</td><td>0.01203</td></tr><tr><td>lr-SGD/group0</td><td>0.001</td></tr><tr><td>trainer/batch_idx</td><td>389</td></tr><tr><td>trainer/global_step</td><td>1950</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">robust-butterfly</strong>: <a href=\"https://wandb.ai/prunes/lth_diet/runs/mk5419dj\" target=\"_blank\">https://wandb.ai/prunes/lth_diet/runs/mk5419dj</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220505_060016-mk5419dj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_1__0 = load_pruned_model(\"model_0\", \"mask_1\", model_hparams)\n",
    "model = model_1__0\n",
    "model.cuda()\n",
    "model.train()\n",
    "max_duration = \"1950ba\"\n",
    "optimizer = SGDHparams(lr=0.001, momentum=0.9, weight_decay=0.0001).initialize_object(model.parameters())\n",
    "scheduler = ConstantSchedulerHparams().initialize_object()\n",
    "seed = 789\n",
    "logger = [WandBLoggerHparams(\"lth_diet\", \"crazy\", entity=\"prunes\").initialize_object()]\n",
    "callback = [LRMonitorHparams().initialize_object()]\n",
    "trainer = Trainer(model=model, \n",
    "                  train_dataloader=train_data, \n",
    "                  max_duration=max_duration, \n",
    "                  eval_dataloader=test_data,\n",
    "                  optimizers=optimizer, \n",
    "                  schedulers=scheduler,\n",
    "                  device=\"gpu\", \n",
    "                  validate_every_n_batches=195, \n",
    "                  validate_every_n_epochs=-1,\n",
    "                  precision=\"amp\", \n",
    "                  seed=seed, \n",
    "                  loggers=logger,\n",
    "                  callbacks=callback,\n",
    "                  save_folder=\"/home/mansheej/lth_diet/ipynbs/crazy/ckpts\",\n",
    "                  save_name_format=\"{batch}ba\",\n",
    "                  save_latest_format=None,\n",
    "                  save_interval=\"195ba\",\n",
    "                  save_weights_only=True)\n",
    "trainer.fit()\n",
    "model.cpu()\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model test accuracy: 91.37% -> It is in the error sublevel set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9136999845504761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_accuracy(model, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this trained model as `model_1__1.pt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.module.state_dict(), \"crazy/model_1__1.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We no longer need `model_1__0` or `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, model_1__0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `model_0` and `model_1__1` so that we can look for LMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = load_pruned_model(\"model_0\", \"mask_0\", model_hparams)\n",
    "model_1__1 = load_pruned_model(\"model_1__1\", \"mask_1\", model_hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for calculating the midpoint state dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midpoint(state_dict, state_dict_):\n",
    "    state_dict__ = {}\n",
    "    for k, v in state_dict.items():\n",
    "        state_dict__[k] = (v + state_dict_[k]) / 2\n",
    "    return state_dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the midpoint state_dict and load it into a `model_mid` which should have `mask_0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = midpoint(model_0.module.state_dict(), model_1__1.module.state_dict())\n",
    "model_mid = model_hparams.initialize_object()\n",
    "model_mid.module.load_state_dict(state_dict)\n",
    "mask = torch.load(f\"crazy/mask_0.pt\")\n",
    "model_mid = PrunedClassifier(model_mid, mask)\n",
    "model_mid.cpu()\n",
    "model_mid.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The midpoint is roughly in the error sublevel set with accuracy 91.29%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9128999710083008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_accuracy(model_mid, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now drop `model_0`, `model_mid` and `mask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_0, model_mid, mask, model_1__1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to prune `mask_1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = PruningHparams(0.2).prune(model_1__1, torch.load(f\"crazy/mask_1.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save `mask_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mask, \"crazy/mask_2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take `model_1__1` and project it with `mask_2` to get `model_2__0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2__0 = load_pruned_model(\"model_1__1\", \"mask_2\", model_hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has the correct sparsity of 64%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6399909853935242"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pruned_model_density(model_2__0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy however has fallen to 90.89%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9088999629020691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_accuracy(model_2__0, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_2__0.module.state_dict(), \"crazy/model_2__0.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_2__0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.13"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mansheej/lth_diet/ipynbs/wandb/run-20220505_065159-3d7saym4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/prunes/lth_diet/runs/3d7saym4\" target=\"_blank\">cherry-puffin</a></strong> to <a href=\"https://wandb.ai/prunes/lth_diet\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040c3e68d0ef4b0989404d04fabf8e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy/val</td><td>▂▅▅▄▆▆█▅▆▁</td></tr><tr><td>crossentropyloss/val</td><td>▅▆▄▅▁▇▄▂█▂</td></tr><tr><td>epoch</td><td>▁▁▃▃▅▅▆▆███</td></tr><tr><td>loss/train</td><td>▄▂▅▁▃▆▂▃▃▂▂▁▄▃▂▃▃█▃▄▂▃▆▂▂▃▃▄▄▁▆▁▂▆▂▃▁▂▂▃</td></tr><tr><td>lr-SGD/group0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/batch_idx</td><td>▁▂▃▄▅▆▇█▁▂▃▄▅▆▇█▁▂▃▄▅▆▇█▁▂▃▄▅▆▇█▁▂▃▄▅▆▇█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy/val</td><td>0.9103</td></tr><tr><td>crossentropyloss/val</td><td>0.3637</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>loss/train</td><td>0.01381</td></tr><tr><td>lr-SGD/group0</td><td>0.001</td></tr><tr><td>trainer/batch_idx</td><td>389</td></tr><tr><td>trainer/global_step</td><td>1950</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">cherry-puffin</strong>: <a href=\"https://wandb.ai/prunes/lth_diet/runs/3d7saym4\" target=\"_blank\">https://wandb.ai/prunes/lth_diet/runs/3d7saym4</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220505_065159-3d7saym4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_pruned_model(\"model_2__0\", \"mask_2\", model_hparams)\n",
    "model.cuda()\n",
    "model.train()\n",
    "max_duration = \"1950ba\"\n",
    "optimizer = SGDHparams(lr=0.001, momentum=0.9, weight_decay=0.0001).initialize_object(model.parameters())\n",
    "scheduler = ConstantSchedulerHparams().initialize_object()\n",
    "seed = 789\n",
    "logger = [WandBLoggerHparams(\"lth_diet\", \"crazy\", entity=\"prunes\").initialize_object()]\n",
    "callback = [LRMonitorHparams().initialize_object()]\n",
    "trainer = Trainer(model=model, \n",
    "                  train_dataloader=train_data, \n",
    "                  max_duration=max_duration, \n",
    "                  eval_dataloader=test_data,\n",
    "                  optimizers=optimizer, \n",
    "                  schedulers=scheduler,\n",
    "                  device=\"gpu\", \n",
    "                  validate_every_n_batches=195, \n",
    "                  validate_every_n_epochs=-1,\n",
    "                  precision=\"amp\", \n",
    "                  seed=seed, \n",
    "                  loggers=logger,\n",
    "                  callbacks=callback,\n",
    "                  save_folder=\"/home/mansheej/lth_diet/ipynbs/crazy/ckpts\",\n",
    "                  save_name_format=\"{batch}ba\",\n",
    "                  save_latest_format=None,\n",
    "                  save_interval=\"195ba\",\n",
    "                  save_weights_only=True)\n",
    "trainer.fit()\n",
    "model.cpu()\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6ede5693076468011a9b06db16dff54c2e2dab3909e284e06b92eee2c289d4c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('lth_diet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
