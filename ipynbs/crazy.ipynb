{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from composer.algorithms import ChannelsLastHparams\n",
    "from composer.callbacks import LRMonitorHparams\n",
    "from composer.core.types import DataLoader\n",
    "from composer.datasets import DataLoaderHparams\n",
    "from composer.loggers import WandBLoggerHparams\n",
    "from composer.models import ComposerClassifier\n",
    "from composer.optim import (SGDHparams, ConstantSchedulerHparams, CosineAnnealingSchedulerHparams, \n",
    "                            CosineAnnealingWithWarmupSchedulerHparams, MultiStepSchedulerHparams, \n",
    "                            MultiStepWithWarmupSchedulerHparams)\n",
    "from composer.trainer import Trainer, TrainerHparams\n",
    "from composer.utils.object_store import ObjectStoreProviderHparams, ObjectStoreProvider\n",
    "from copy import deepcopy\n",
    "from lth_diet.data import CIFAR10DataHparams, DataHparams\n",
    "from lth_diet.exps import LotteryExperiment\n",
    "from lth_diet.models import ResNetCIFARClassifierHparams, ClassifierHparams\n",
    "from lth_diet.pruning import Mask, PrunedClassifier, PruningHparams\n",
    "from lth_diet.pruning.pruned_classifier import prunable_layer_names\n",
    "from lth_diet.utils import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from typing import Callable, Tuple\n",
    "plt.style.use(\"default\")\n",
    "rc = {\"figure.figsize\": (4, 3), \"figure.dpi\": 150, \"figure.constrained_layout.use\": True, \"axes.grid\": True, \n",
    "      \"axes.spines.right\": False, \"axes.spines.top\": False, \"axes.linewidth\": 0.6, \"grid.linewidth\": 0.6,\n",
    "      \"xtick.major.width\": 0.6, \"ytick.major.width\": 0.6, \"xtick.major.size\": 4, \"ytick.major.size\": 4, \n",
    "      \"axes.labelsize\": 11, \"axes.titlesize\": 11, \"xtick.labelsize\": 10, \"ytick.labelsize\": 10,\n",
    "      \"axes.titlepad\": 4, \"axes.labelpad\": 2, \"xtick.major.pad\": 2, \"ytick.major.pad\": 2,\n",
    "      \"lines.linewidth\": 1.2, 'lines.markeredgecolor': 'w', \"patch.linewidth\": 0}\n",
    "sns.set_theme(style='ticks', palette=sns.color_palette(\"tab10\"), rc=rc)\n",
    "object_store = ObjectStoreProviderHparams('google_storage', 'prunes', 'GCS_KEY').initialize_object()\n",
    "bucket_dir = os.environ['OBJECT_STORE_DIR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a checkpoint from the cloud and make a PrunedClassifier\n",
    "def load_pruned_model_from_cloud(\n",
    "    exp: LotteryExperiment,\n",
    "    replicate: int,\n",
    "    level: int,\n",
    "    ckpt: str,\n",
    "    model_hparams: ClassifierHparams,\n",
    "    object_store: ObjectStoreProvider,\n",
    ") -> PrunedClassifier:\n",
    "    location = f\"{utils.get_hash(exp.name)}/replicate_{replicate}/level_{level}/main\"\n",
    "    name = f\"model_{ckpt}.pt\"\n",
    "    state_dict = utils.load_object(location, name, object_store, torch.load)\n",
    "    model = model_hparams.initialize_object()\n",
    "    model.module.load_state_dict(state_dict)\n",
    "    mask = Mask.load(location, object_store)\n",
    "    model = PrunedClassifier(model, mask)\n",
    "    model.cpu()\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Load a mask from the cloud\n",
    "def load_mask_from_cloud(exp: LotteryExperiment, replicate: int, level: int, object_store: ObjectStoreProvider) -> Mask:\n",
    "    location = f\"{utils.get_hash(exp.name)}/replicate_{replicate}/level_{level}/main\"\n",
    "    mask = Mask.load(location, object_store)\n",
    "    return mask\n",
    "\n",
    "# Calculate density of the pruned model\n",
    "def get_pruned_model_density(model: PrunedClassifier) -> float:\n",
    "    names = [PrunedClassifier.to_mask_name(name) for name in prunable_layer_names(model)]\n",
    "    params = torch.cat([getattr(model, name).flatten() for name in names])\n",
    "    return (params != 0).float().mean().item()\n",
    "\n",
    "# Calculate accuracy of model on data\n",
    "def get_accuracy(model: ComposerClassifier, data: DataLoader) -> float:\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for batch in tqdm(data):\n",
    "        batch = batch[0].cuda(), batch[1].cuda()\n",
    "        logits = model(batch)\n",
    "        correct += (logits.argmax(dim=-1) == batch[1]).sum()\n",
    "    model.cpu()\n",
    "    return (correct / len(data.dataset)).item()\n",
    "\n",
    "# Save a model ckpt\n",
    "def save_model(model: ComposerClassifier, name: str) -> None:\n",
    "    path_ckpt = f\"crazy/{name}.pt\"\n",
    "    torch.save(model.module.state_dict(), path_ckpt)\n",
    "\n",
    "# Save a mask\n",
    "def save_mask(mask: Mask, name: str) -> None:\n",
    "    path_mask = f\"crazy/{name}.pt\"\n",
    "    torch.save(mask, path_mask)\n",
    "    \n",
    "# Load a mask\n",
    "def load_mask(name: str) -> Mask:\n",
    "    return torch.load(f\"crazy/{name}.pt\")\n",
    "\n",
    "# Load a pruned classifier from a model ckpt and a saved mask\n",
    "def load_model(model_name: str, mask_name: str, model_hparams: ClassifierHparams) -> PrunedClassifier:\n",
    "    state_dict = torch.load(f\"crazy/{model_name}.pt\")\n",
    "    model = model_hparams.initialize_object()\n",
    "    model.module.load_state_dict(state_dict)\n",
    "    mask = load_mask(mask_name)\n",
    "    model = PrunedClassifier(model, mask)\n",
    "    model.cpu()\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# get the midpoint of 2 state_dicts\n",
    "def midpoint(state_dict, state_dict_):\n",
    "    state_dict__ = {}\n",
    "    for k, v in state_dict.items():\n",
    "        state_dict__[k] = (v + state_dict_[k]) / 2\n",
    "    return state_dict__\n",
    "\n",
    "# compare 2 models to their midpoint on data using eval_fn\n",
    "def compare_to_midpoint(\n",
    "    model_a_name: str,\n",
    "    mask_a_name: str,\n",
    "    model_b_name: str,\n",
    "    mask_b_name: str,\n",
    "    data: DataLoader,\n",
    "    eval_fn: Callable,\n",
    "    model_hparams: ClassifierHparams,\n",
    ") -> Tuple[float, float, float]:\n",
    "    model_a = load_model(model_a_name, mask_a_name, model_hparams)\n",
    "    output_a = eval_fn(model_a, data)\n",
    "    model_b = load_model(model_b_name, mask_b_name, model_hparams)\n",
    "    output_b = eval_fn(model_b, data)\n",
    "    state_dict = midpoint(model_a.module.state_dict(), model_b.module.state_dict())\n",
    "    model = model_hparams.initialize_object()\n",
    "    model.module.load_state_dict(state_dict)\n",
    "    assert(get_pruned_model_density(model_a) >= get_pruned_model_density(model_b))\n",
    "    mask = load_mask(mask_a_name)\n",
    "    model = PrunedClassifier(model, mask)\n",
    "    model.cpu()\n",
    "    model.eval()\n",
    "    output = eval_fn(model, data)\n",
    "    return (output_a, output, output_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use LotteryExperiment with rewinding step = 2000ba as it did the well and I want to start by using a late rewinding step.  \n",
    "Use replicate 3, no good reason.  \n",
    "Start at level 1 because there is a small error bump between level 0 and level 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lottery(model=ResNetCIFAR(num_classes=10,num_layers=20),train_data=CIFAR10(train=True),train_batch_size=128,optimizer=SGDHparams(lr=0.1,momentum=0.9,weight_decay=0.0001,dampening=0.0,nesterov=False),schedulers=[MultiStepSchedulerHparams(milestones=[31200ba,46800ba],gamma=0.1)],max_duration=62400ba,seed=6174,rewinding_steps=2000ba,pruning=PruningHparams(pruning_fraction=0.2),algorithms=[ChannelsLastHparams()],callbacks=[LRMonitorHparams()]) 3 1\n"
     ]
    }
   ],
   "source": [
    "config = \"../configs/lottery_test.yaml\"\n",
    "exp = LotteryExperiment.create(config, cli_args=False)\n",
    "exp.rewinding_steps = \"2000ba\"\n",
    "replicate = 3\n",
    "level = 1\n",
    "print(exp.name, replicate, level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare train and test dataloaders as well as model hparams.  \n",
    "Train batch size = 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CIFAR10DataHparams(True).initialize_object(128, DataLoaderHparams(persistent_workers=False))\n",
    "test_data = CIFAR10DataHparams(False).initialize_object(1000, DataLoaderHparams(persistent_workers=False))\n",
    "model_hparams = ResNetCIFARClassifierHparams(10, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the final model from replicate 3 level 1 as a PrunedClassifier. Also load the mask for level 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_pruned_model_from_cloud(exp, replicate, level, \"final\", model_hparams, object_store)\n",
    "# mask = load_mask_from_cloud(exp, replicate, level, object_store)\n",
    "model = load_model(\"model_1__1\", \"mask_1\", model_hparams)\n",
    "mask = load_mask(\"mask_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the density of the model and the mask and the accuracy of the model.  \n",
    "Both the mask and the model have density = 80%.  \n",
    "The model achieves test accuracy = 91.76%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask density: 0.7999933362007141\n",
      "Model density: 0.7999933362007141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test accuracy: 0.9175999760627747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Mask density:\", mask.density.item())\n",
    "print(\"Model density:\", get_pruned_model_density(model))\n",
    "print(\"Model test accuracy:\", get_accuracy(model, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the level 1 final model and mask as `model_1__1` and `mask_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model(model, \"model_1__1\")\n",
    "# save_mask(mask, \"mask_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Magnitude prune 20% of the remaining weights of `model_1__1` (`mask_1`) to generate `mask_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model_1__1\", \"mask_1\", model_hparams)\n",
    "mask = load_mask(\"mask_1\")\n",
    "pruning_fraction = 0.2\n",
    "mask = PruningHparams(pruning_fraction).prune(model, mask)\n",
    "# save_mask(mask, \"mask_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check `mask_2`. It should have 64% of weights remaining and should be identical to the mask in level 2 in the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6399909853935242\n",
      "Sanity check passed\n"
     ]
    }
   ],
   "source": [
    "def sanity_check():\n",
    "    mask = load_mask(\"mask_2\")\n",
    "    print(mask.density.item())\n",
    "    test_mask = load_mask_from_cloud(exp, replicate, 2, object_store)\n",
    "    for k, v in test_mask.items():\n",
    "        if not (v == mask[k]).all().item():\n",
    "            print(\"Sanity check failed\")\n",
    "            return\n",
    "    print(\"Sanity check passed\")\n",
    "    return\n",
    "\n",
    "sanity_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we construct `model_2__0` by applying `mask_2` to `model_1__1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model_1__1\", \"mask_2\", model_hparams)\n",
    "# save_model(model, \"model_2__0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the density and accuracy of `model_2__0`?  \n",
    "Density = 64%  \n",
    "Test Accuracy = 91.84%  \n",
    "`model_2__0` is even better than `model_1__1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model density: 0.6399909853935242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test accuracy: 0.91839998960495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"model_2__0\", \"mask_2\", model_hparams)\n",
    "print(\"Model density:\", get_pruned_model_density(model))\n",
    "print(\"Model test accuracy:\", get_accuracy(model, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the test accuracy of `model_1__1`, `model_2__0`, and the midpoint between them. For the midpoint, we use the mask of the denser model.  \n",
    "`model_1__1` = 91.76%  \n",
    "midpoint = 91.87%  \n",
    "`model_2__0` = 91.84%  \n",
    "Both models are linearly connected in the same error sublevel set. We call them ***ERROR CONNECTED***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.90it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 10.71it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 10.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of (model_denser, model_midpoint, model_sparser) = (0.9175999760627747, 0.9187999963760376, 0.91839998960495)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Test accuracy of (model_denser, model_midpoint, model_sparser) =\",\n",
    "    compare_to_midpoint(\"model_1__1\", \"mask_1\", \"model_2__0\", \"mask_2\", test_data, get_accuracy, model_hparams)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of this lovely property, `model_2__1` will just be `model_2__0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model_2__0\", \"mask_2\", model_hparams)\n",
    "# save_model(model, \"model_2__1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Magnitude prune 20% of the remaining weights of `model_2__1` (`mask_2`) to generate `mask_3` which has 51% of the weights remaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask density = 0.5119861364364624\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"model_2__1\", \"mask_2\", model_hparams)\n",
    "mask = load_mask(\"mask_2\")\n",
    "pruning_fraction = 0.2\n",
    "mask = PruningHparams(pruning_fraction).prune(model, mask)\n",
    "print(\"Mask density =\", mask.density.item())\n",
    "# save_mask(mask, \"mask_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we construct `model_3__0` by applying `mask_3` to `model_2__1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model_2__1\", \"mask_3\", model_hparams)\n",
    "# save_model(model, \"model_3__0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the density and accuracy of `model_3__0`?  \n",
    "Density = 51%  \n",
    "Test Accuracy = 91.01%  \n",
    "`model_3__0` is not as good and needs further training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model density: 0.5119861364364624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test accuracy: 0.910099983215332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"model_3__0\", \"mask_3\", model_hparams)\n",
    "print(\"Model density:\", get_pruned_model_density(model))\n",
    "print(\"Model test accuracy:\", get_accuracy(model, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried a bunch of different training hyperparameters. This seemed to work. Saving models along the way so we can load a good one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(\"model_3__0\", \"mask_3\", model_hparams)\n",
    "# model.cuda()\n",
    "# model.train()\n",
    "# max_duration = \"7800ba\"\n",
    "# algorithms = [ChannelsLastHparams().initialize_object()]\n",
    "# optimizer = SGDHparams(lr=0.001, momentum=0.9, weight_decay=0.0001).initialize_object(model.parameters())\n",
    "# scheduler = CosineAnnealingWithWarmupSchedulerHparams(t_warmup=\"3120ba\", alpha_f=0.0).initialize_object()\n",
    "# seed = 789\n",
    "# logger = [WandBLoggerHparams(\"lth_diet\", \"crazy\", entity=\"prunes\").initialize_object()]\n",
    "# callback = [LRMonitorHparams().initialize_object()]\n",
    "# trainer = Trainer(model=model, \n",
    "#                   train_dataloader=train_data, \n",
    "#                   max_duration=max_duration, \n",
    "#                   eval_dataloader=test_data,\n",
    "#                   algorithms=algorithms,\n",
    "#                   optimizers=optimizer, \n",
    "#                   schedulers=scheduler,\n",
    "#                   device=\"gpu\", \n",
    "#                   validate_every_n_batches=195, \n",
    "#                   validate_every_n_epochs=-1,\n",
    "#                   precision=\"amp\", \n",
    "#                   seed=seed, \n",
    "#                   loggers=logger,\n",
    "#                   callbacks=callback,\n",
    "#                   save_folder=\"/home/mansheej/lth_diet/ipynbs/crazy/ckpts\",\n",
    "#                   save_name_format=\"{batch}ba\",\n",
    "#                   save_latest_format=None,\n",
    "#                   save_interval=\"195ba\",\n",
    "#                   save_weights_only=True)\n",
    "# trainer.fit()\n",
    "# model.cpu()\n",
    "# model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model at 4680ba worked pretty well. Load in the composer format and save to our format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(\"model_3__0\", \"mask_3\", model_hparams)\n",
    "# state_dict = torch.load(\"crazy/ckpts/4680ba\")\n",
    "# model.load_state_dict(state_dict[\"state\"][\"model\"])\n",
    "# model._apply_mask()\n",
    "# save_model(model, \"model_3__1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained model at level 3: `model_3__1`  \n",
    "Density = 51%  \n",
    "Test Accuracy = 91.77%  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model density: 0.5119861364364624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test accuracy: 0.9176999926567078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"model_3__1\", \"mask_3\", model_hparams)\n",
    "print(\"Model density:\", get_pruned_model_density(model))\n",
    "print(\"Model test accuracy:\", get_accuracy(model, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we check that model that `model_2__1` and `mmodel_3__1` are indeed ***ERROR CONNECTED***.  \n",
    "Test accuracy `model_2__1` = 91.84%  \n",
    "Test accuracy midpoint = 91.86%  \n",
    "Test accuracy `model_3__1` = 91.77%  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.18it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 10.82it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of (model_denser, model_midpoint, model_sparser) = (0.91839998960495, 0.9185999631881714, 0.9176999926567078)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Test accuracy of (model_denser, model_midpoint, model_sparser) =\",\n",
    "    compare_to_midpoint(\"model_2__1\", \"mask_2\", \"model_3__1\", \"mask_3\", test_data, get_accuracy, model_hparams)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to see if `mask_3`, which was obtained through Subelevel Error Search can be applied to the dense model at the rewind step such that the model successfully trains to high test accuracy into the same error sublevel set.  \n",
    "Load the dense rewind model from the cloud and save it as `model_rewind`. This model is the initial model in level 0. For `model_rewind`:  \n",
    "Density = 100%  \n",
    "Test Accuracy = 68.96%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model density: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test accuracy: 0.6895999908447266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_pruned_model_from_cloud(exp, replicate, 0, \"init\", model_hparams, object_store)\n",
    "print(\"Model density:\", get_pruned_model_density(model))\n",
    "print(\"Model test accuracy:\", get_accuracy(model, test_data))\n",
    "# save_model(model, \"model_rewind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply `mask_3` to `model_rewind` to get `model_3__i`. `model_3__i` should have a density of 51% and low test accuracy. Indeed, for `model_3__i`,  \n",
    "Density = 51%  \n",
    "Test Accuracy = 15.01%  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model density: 0.5119861364364624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test accuracy: 0.1500999927520752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"model_rewind\", \"mask_3\", model_hparams)\n",
    "print(\"Model density:\", get_pruned_model_density(model))\n",
    "print(\"Model test accuracy:\", get_accuracy(model, test_data))\n",
    "# save_model(model, \"model_3__i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train `model_3__i` using the same hyperparameters as the dense model accounting for the fact that 2000 batches of pretraining is complete. This is testing if the mask obtained without rewinding can be used to train a model that has been rewinded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(\"model_3__i\", \"mask_3\", model_hparams)\n",
    "# model.cuda()\n",
    "# model.train()\n",
    "# max_duration = \"60400ba\"\n",
    "# algorithms = [ChannelsLastHparams().initialize_object()]\n",
    "# optimizer = SGDHparams(lr=0.1, momentum=0.9, weight_decay=0.0001).initialize_object(model.parameters())\n",
    "# scheduler = MultiStepSchedulerHparams(milestones=[\"29200ba\", \"44800ba\"], gamma=0.1).initialize_object()\n",
    "# seed = 6174\n",
    "# logger = [WandBLoggerHparams(\"lth_diet\", \"crazy\", entity=\"prunes\").initialize_object()]\n",
    "# callback = [LRMonitorHparams().initialize_object()]\n",
    "# trainer = Trainer(\n",
    "#     model=model, \n",
    "#     train_dataloader=train_data, \n",
    "#     max_duration=max_duration, \n",
    "#     eval_dataloader=test_data,\n",
    "#     algorithms=algorithms,\n",
    "#     optimizers=optimizer, \n",
    "#     schedulers=scheduler,\n",
    "#     device=\"gpu\", \n",
    "#     # validate_every_n_batches=195, \n",
    "#     # validate_every_n_epochs=-1,\n",
    "#     precision=\"amp\", \n",
    "#     step_schedulers_every_batch=True,\n",
    "#     seed=seed, \n",
    "#     loggers=logger,\n",
    "#     callbacks=callback,\n",
    "#     # save_folder=\"/home/mansheej/lth_diet/ipynbs/crazy/ckpts\",\n",
    "#     # save_name_format=\"{batch}ba\",\n",
    "#     # save_latest_format=None,\n",
    "#     # save_interval=\"195ba\",\n",
    "#     # save_weights_only=True)\n",
    "# )\n",
    "# trainer.fit()\n",
    "# model.cpu()\n",
    "# model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the model trained from the rewind point but with `mask_3` as `model_3__f`. It has\n",
    "Density = 51%\n",
    "Test Accuracy = 91.64%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_model(\"model_3__f\", \"mask_3\",)\n",
    "# print(\"Model density:\", get_pruned_model_density(model))\n",
    "# print(\"Model test accuracy:\", get_accuracy(model, test_data))\n",
    "# # save_model(model, \"model_3__f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarkably `model_3__f` and `mmodel_3__1` are indeed ***ERROR CONNECTED***.\n",
    "Test accuracy `model_3__f` = 91.84%  \n",
    "Test accuracy midpoint = 91.86%  \n",
    "Test accuracy `model_3__1` = 91.77%  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\n",
    "#     \"Test accuracy of (model_denser, model_midpoint, model_sparser) =\",\n",
    "#     compare_to_midpoint(\"model_3__f\", \"mask_3\", \"model_3__1\", \"mask_3\", test_data, get_accuracy, model_hparams)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Magnitude prune 20% of the remaining weights of `model_3__1` (`mask_3`) to generate `mask_4` which has 41% of the weights remaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask density = 0.40958523750305176\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"model_3__1\", \"mask_3\", model_hparams)\n",
    "mask = load_mask(\"mask_3\")\n",
    "pruning_fraction = 0.2\n",
    "mask = PruningHparams(pruning_fraction).prune(model, mask)\n",
    "print(\"Mask density =\", mask.density.item())\n",
    "# save_mask(mask, \"mask_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we construct `model_4__0` by applying `mask_4` to `model_3__1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model_3__1\", \"mask_4\", model_hparams)\n",
    "# save_model(model, \"model_4__0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the density and accuracy of `model_4__0`?  \n",
    "Density = 41%  \n",
    "Test Accuracy = 89.05%  \n",
    "`model_4__0` is not as good and needs further training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model density: 0.40958523750305176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test accuracy: 0.8904999494552612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"model_4__0\", \"mask_4\", model_hparams)\n",
    "print(\"Model density:\", get_pruned_model_density(model))\n",
    "print(\"Model test accuracy:\", get_accuracy(model, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(\"model_4__0\", \"mask_4\", model_hparams)\n",
    "# model.cuda()\n",
    "# model.train()\n",
    "# max_duration = \"7800ba\"\n",
    "# algorithms = [ChannelsLastHparams().initialize_object()]\n",
    "# optimizer = SGDHparams(lr=0.01, momentum=0.9, weight_decay=0.0001).initialize_object(model.parameters())\n",
    "# scheduler = MultiStepSchedulerHparams(gamma=0.1, milestones=[\"3120ba\"]).initialize_object()\n",
    "# seed = 1234\n",
    "# logger = [WandBLoggerHparams(\"lth_diet\", \"crazy\", entity=\"prunes\").initialize_object()]\n",
    "# callback = [LRMonitorHparams().initialize_object()]\n",
    "# trainer = Trainer(model=model, \n",
    "#                   train_dataloader=train_data, \n",
    "#                   max_duration=max_duration, \n",
    "#                   eval_dataloader=test_data,\n",
    "#                   algorithms=algorithms,\n",
    "#                   optimizers=optimizer, \n",
    "#                   schedulers=scheduler,\n",
    "#                   device=\"gpu\", \n",
    "#                   validate_every_n_batches=195, \n",
    "#                   validate_every_n_epochs=-1,\n",
    "#                   precision=\"amp\", \n",
    "#                   seed=seed, \n",
    "#                   loggers=logger,\n",
    "#                   callbacks=callback,\n",
    "#                   save_folder=\"/home/mansheej/lth_diet/ipynbs/crazy/ckpts\",\n",
    "#                   save_name_format=\"{batch}ba\",\n",
    "#                   save_latest_format=None,\n",
    "#                   save_interval=\"195ba\",\n",
    "#                   save_weights_only=True)\n",
    "# trainer.fit()\n",
    "# model.cpu()\n",
    "# model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model at 5265ba worked pretty well. Load in the composer format and save to our format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(\"model_4__0\", \"mask_4\", model_hparams)\n",
    "# state_dict = torch.load(\"crazy/ckpts/5265ba\")\n",
    "# model.load_state_dict(state_dict[\"state\"][\"model\"])\n",
    "# model._apply_mask()\n",
    "# save_model(model, \"model_4__1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained model at level 4: `model_4__1`  \n",
    "Density = 41%  \n",
    "Test Accuracy = 91.62%  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model density: 0.40958523750305176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test accuracy: 0.9161999821662903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"model_4__1\", \"mask_4\", model_hparams)\n",
    "print(\"Model density:\", get_pruned_model_density(model))\n",
    "print(\"Model test accuracy:\", get_accuracy(model, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we check that model that `model_3__1` and `model_4__1` are indeed ***ERROR CONNECTED***.  \n",
    "Test accuracy `model_3__1` = 91.77%  \n",
    "Test accuracy midpoint = 91.62%  \n",
    "Test accuracy `model_4__1` = 91.62%  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.08it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.70it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of (model_denser, model_midpoint, model_sparser) = (0.9176999926567078, 0.9161999821662903, 0.9161999821662903)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Test accuracy of (model_denser, model_midpoint, model_sparser) =\",\n",
    "    compare_to_midpoint(\"model_3__1\", \"mask_3\", \"model_4__1\", \"mask_4\", test_data, get_accuracy, model_hparams)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply `mask_4` to `model_rewind` to get `model_4__i`. `model_4__i` should have a density of 41% and low test accuracy. Indeed, for `model_4__i`,  \n",
    "Density = 41%  \n",
    "Test Accuracy = 10.29%  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model density: 0.40958523750305176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test accuracy: 0.10289999842643738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"model_rewind\", \"mask_4\", model_hparams)\n",
    "print(\"Model density:\", get_pruned_model_density(model))\n",
    "print(\"Model test accuracy:\", get_accuracy(model, test_data))\n",
    "# save_model(model, \"model_4__i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train `model_4__i` using the same hyperparameters as the dense model accounting for the fact that 2000 batches of pretraining is complete. This is testing if the mask obtained without rewinding can be used to train a model that has been rewinded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(\"model_4__i\", \"mask_4\", model_hparams)\n",
    "# model.cuda()\n",
    "# model.train()\n",
    "# max_duration = \"60400ba\"\n",
    "# algorithms = [ChannelsLastHparams().initialize_object()]\n",
    "# optimizer = SGDHparams(lr=0.1, momentum=0.9, weight_decay=0.0001).initialize_object(model.parameters())\n",
    "# scheduler = MultiStepSchedulerHparams(milestones=[\"29200ba\", \"44800ba\"], gamma=0.1).initialize_object()\n",
    "# seed = 6174\n",
    "# logger = [WandBLoggerHparams(\"lth_diet\", \"crazy\", entity=\"prunes\").initialize_object()]\n",
    "# callback = [LRMonitorHparams().initialize_object()]\n",
    "# trainer = Trainer(\n",
    "#     model=model, \n",
    "#     train_dataloader=train_data, \n",
    "#     max_duration=max_duration, \n",
    "#     eval_dataloader=test_data,\n",
    "#     algorithms=algorithms,\n",
    "#     optimizers=optimizer, \n",
    "#     schedulers=scheduler,\n",
    "#     device=\"gpu\", \n",
    "#     # validate_every_n_batches=195, \n",
    "#     # validate_every_n_epochs=-1,\n",
    "#     precision=\"amp\", \n",
    "#     step_schedulers_every_batch=True,\n",
    "#     seed=seed, \n",
    "#     loggers=logger,\n",
    "#     callbacks=callback,\n",
    "#     # save_folder=\"/home/mansheej/lth_diet/ipynbs/crazy/ckpts\",\n",
    "#     # save_name_format=\"{batch}ba\",\n",
    "#     # save_latest_format=None,\n",
    "#     # save_interval=\"195ba\",\n",
    "#     # save_weights_only=True)\n",
    "# )\n",
    "# trainer.fit()\n",
    "# model.cpu()\n",
    "# model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the model trained from the rewind point but with `mask_4` as `model_4__f`. It has\n",
    "Density = 41%\n",
    "Test Accuracy = 91.79%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model density: 0.40958523750305176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test accuracy: 0.9178999662399292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"model_4__f\", \"mask_4\", model_hparams)\n",
    "print(\"Model density:\", get_pruned_model_density(model))\n",
    "print(\"Model test accuracy:\", get_accuracy(model, test_data))\n",
    "# save_model(model, \"model_4__f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarkably `model_4__f` and `mmodel_4__1` are indeed ***ERROR CONNECTED***.\n",
    "Test accuracy `model_4__f` = 91.79%  \n",
    "Test accuracy midpoint = 91.92%  \n",
    "Test accuracy `model_4__1` = 91.62%  \n",
    "This is working phenomenally!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.43it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 10.81it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  9.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of (model_denser, model_midpoint, model_sparser) = (0.9178999662399292, 0.9192000031471252, 0.9161999821662903)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Test accuracy of (model_denser, model_midpoint, model_sparser) =\",\n",
    "    compare_to_midpoint(\"model_4__f\", \"mask_4\", \"model_4__1\", \"mask_4\", test_data, get_accuracy, model_hparams)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Magnitude prune 20% of the remaining weights of `model_4__1` (`mask_4`) to generate `mask_5` which has 33% of the weights remaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask density = 0.32766449451446533\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"model_4__1\", \"mask_4\", model_hparams)\n",
    "mask = load_mask(\"mask_4\")\n",
    "pruning_fraction = 0.2\n",
    "mask = PruningHparams(pruning_fraction).prune(model, mask)\n",
    "print(\"Mask density =\", mask.density.item())\n",
    "save_mask(mask, \"mask_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we construct `model_5__0` by applying `mask_5` to `model_4__1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model_4__1\", \"mask_5\", model_hparams)\n",
    "save_model(model, \"model_5__0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the density and accuracy of `model_5__0`?  \n",
    "Density = 33%  \n",
    "Test Accuracy = 86.74%  \n",
    "`model_5__0` is not as good and needs further training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model density: 0.32766449451446533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test accuracy: 0.8673999905586243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"model_5__0\", \"mask_5\", model_hparams)\n",
    "print(\"Model density:\", get_pruned_model_density(model))\n",
    "print(\"Model test accuracy:\", get_accuracy(model, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.13"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mansheej/lth_diet/ipynbs/wandb/run-20220506_072853-3negtji2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/prunes/lth_diet/runs/3negtji2\" target=\"_blank\">voracious-lemming</a></strong> to <a href=\"https://wandb.ai/prunes/lth_diet\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3718122de33c432dafd9c8b912be9f0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td><composer.algorithms.channels_last.channels_last.ChannelsLast object at 0x7f93641141c0>/Event.INIT</td><td>▁</td></tr><tr><td>accuracy/val</td><td>▁▂▄▁▄▃▇▅▅▆▆█▇▇▇▆▆▇▇▆▇█▇▇▇▇▇▆▇▇▇█▇▆▆█▇▇█▇</td></tr><tr><td>crossentropyloss/val</td><td>█▄▇█▅▆▄▆▄▃▃▂▃▂▃▂▁▃▂▂▃▃▂▂▃▂▂▃▃▂▃▃▃▄▄▄▄▃▄▄</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>loss/train</td><td>▆█▆▇▃▄▄▃▇▅█▅▃▂▆▂▄▅▄▂▃▂▁▃▂▅▅▃▂▁▃▂▂▄▄▁▄▄▃▁</td></tr><tr><td>lr-SGD/group0</td><td>████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/batch_idx</td><td>▂▆▂▆▂▆▁▆▁▆▁▆▁▇▂▇▂▇▂▆▂▆▂▆▂▆▃▇▃▇▃▇▃▇▂▇▂▇▂█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td><composer.algorithms.channels_last.channels_last.ChannelsLast object at 0x7f93641141c0>/Event.INIT</td><td>1</td></tr><tr><td>accuracy/val</td><td>0.9147</td></tr><tr><td>crossentropyloss/val</td><td>0.34235</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>loss/train</td><td>0.02422</td></tr><tr><td>lr-SGD/group0</td><td>0.001</td></tr><tr><td>trainer/batch_idx</td><td>389</td></tr><tr><td>trainer/global_step</td><td>7800</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">voracious-lemming</strong>: <a href=\"https://wandb.ai/prunes/lth_diet/runs/3negtji2\" target=\"_blank\">https://wandb.ai/prunes/lth_diet/runs/3negtji2</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220506_072853-3negtji2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model(\"model_5__0\", \"mask_5\", model_hparams)\n",
    "model.cuda()\n",
    "model.train()\n",
    "max_duration = \"7800ba\"\n",
    "algorithms = [ChannelsLastHparams().initialize_object()]\n",
    "optimizer = SGDHparams(lr=0.01, momentum=0.9, weight_decay=0.0001).initialize_object(model.parameters())\n",
    "# scheduler = ConstantSchedulerHparams().initialize_object()\n",
    "# scheduler = CosineAnnealingSchedulerHparams().initialize_object()\n",
    "scheduler = MultiStepSchedulerHparams(gamma=0.1, milestones=[\"1560ba\"]).initialize_object()\n",
    "seed = 7890\n",
    "logger = [WandBLoggerHparams(\"lth_diet\", \"crazy\", entity=\"prunes\").initialize_object()]\n",
    "callback = [LRMonitorHparams().initialize_object()]\n",
    "trainer = Trainer(model=model, \n",
    "                  train_dataloader=train_data, \n",
    "                  max_duration=max_duration, \n",
    "                  eval_dataloader=test_data,\n",
    "                  algorithms=algorithms,\n",
    "                  optimizers=optimizer, \n",
    "                  schedulers=scheduler,\n",
    "                  device=\"gpu\", \n",
    "                  validate_every_n_batches=195, \n",
    "                  validate_every_n_epochs=-1,\n",
    "                  precision=\"amp\", \n",
    "                  seed=seed, \n",
    "                  loggers=logger,\n",
    "                  callbacks=callback,\n",
    "                  save_folder=\"/home/mansheej/lth_diet/ipynbs/crazy/ckpts\",\n",
    "                  save_name_format=\"{batch}ba\",\n",
    "                  save_latest_format=None,\n",
    "                  save_interval=\"195ba\",\n",
    "                  save_weights_only=True)\n",
    "trainer.fit()\n",
    "model.cpu()\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model at 7605ba worked pretty well. Load in the composer format and save to our format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model_5__0\", \"mask_5\", model_hparams)\n",
    "state_dict = torch.load(\"crazy/ckpts/7605ba\")\n",
    "model.load_state_dict(state_dict[\"state\"][\"model\"])\n",
    "model._apply_mask()\n",
    "save_model(model, \"model_5__1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained model at level 5: `model_5__1`  \n",
    "Density = 33%  \n",
    "Test Accuracy = 91.52%  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model density: 0.32766449451446533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test accuracy: 0.9151999950408936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"model_5__1\", \"mask_5\", model_hparams)\n",
    "print(\"Model density:\", get_pruned_model_density(model))\n",
    "print(\"Model test accuracy:\", get_accuracy(model, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we check that model that `model_4__1` and `model_5__1` are indeed ***ERROR CONNECTED***.  \n",
    "Test accuracy `model_4__1` = 91.62%  \n",
    "Test accuracy midpoint = 91.78%  \n",
    "Test accuracy `model_5__1` = 91.52%  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.38it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 10.39it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of (model_denser, model_midpoint, model_sparser) = (0.9161999821662903, 0.9177999496459961, 0.9151999950408936)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Test accuracy of (model_denser, model_midpoint, model_sparser) =\",\n",
    "    compare_to_midpoint(\"model_4__1\", \"mask_4\", \"model_5__1\", \"mask_5\", test_data, get_accuracy, model_hparams)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply `mask_5` to `model_rewind` to get `model_5__i`. `model_5__i` should have a density of 33% and low test accuracy. Indeed, for `model_5__i`,  \n",
    "Density = 33%  \n",
    "Test Accuracy = 10%  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model density: 0.32766449451446533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test accuracy: 0.09999999403953552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"model_rewind\", \"mask_5\", model_hparams)\n",
    "print(\"Model density:\", get_pruned_model_density(model))\n",
    "print(\"Model test accuracy:\", get_accuracy(model, test_data))\n",
    "save_model(model, \"model_5__i\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train `model_5__i` using the same hyperparameters as the dense model accounting for the fact that 2000 batches of pretraining is complete. This is testing if the mask obtained without rewinding can be used to train a model that has been rewinded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.13"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mansheej/lth_diet/ipynbs/wandb/run-20220506_073843-1kb5zq0x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/prunes/lth_diet/runs/1kb5zq0x\" target=\"_blank\">keen-angora</a></strong> to <a href=\"https://wandb.ai/prunes/lth_diet\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26596a1457eb4ceeaf20f702bdfbeada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td><composer.algorithms.channels_last.channels_last.ChannelsLast object at 0x7f938ed64880>/Event.INIT</td><td>▁</td></tr><tr><td>accuracy/val</td><td>▁▄▅▅▅▅▇▆▅▆▇▆▆▆▆▆▆▆▆█████████████████████</td></tr><tr><td>crossentropyloss/val</td><td>█▅▃▃▃▄▂▃▄▄▂▃▃▃▄▃▂▃▃▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss/train</td><td>█▇▆▆▅▄▄▄▄▅▃▃▅▅▃▃▄▃▂▅▂▂▃▂▁▂▁▁▁▁▁▁▁▂▂▁▁▂▁▁</td></tr><tr><td>lr-SGD/group0</td><td>████████████████████▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/batch_idx</td><td>▃█▇▇▆▆▆▅▅▄▄▃▃▂▂▁▁█▇▇▇▆▆▅▅▄▄▃▃▂▂▂▁██▇▇▆▆▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td><composer.algorithms.channels_last.channels_last.ChannelsLast object at 0x7f938ed64880>/Event.INIT</td><td>1</td></tr><tr><td>accuracy/val</td><td>0.9156</td></tr><tr><td>crossentropyloss/val</td><td>0.3508</td></tr><tr><td>epoch</td><td>155</td></tr><tr><td>loss/train</td><td>0.03535</td></tr><tr><td>lr-SGD/group0</td><td>0.001</td></tr><tr><td>trainer/batch_idx</td><td>339</td></tr><tr><td>trainer/global_step</td><td>60400</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">keen-angora</strong>: <a href=\"https://wandb.ai/prunes/lth_diet/runs/1kb5zq0x\" target=\"_blank\">https://wandb.ai/prunes/lth_diet/runs/1kb5zq0x</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220506_073843-1kb5zq0x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = load_model(\"model_5__i\", \"mask_5\", model_hparams)\n",
    "model.cuda()\n",
    "model.train()\n",
    "max_duration = \"60400ba\"\n",
    "algorithms = [ChannelsLastHparams().initialize_object()]\n",
    "optimizer = SGDHparams(lr=0.1, momentum=0.9, weight_decay=0.0001).initialize_object(model.parameters())\n",
    "scheduler = MultiStepSchedulerHparams(milestones=[\"29200ba\", \"44800ba\"], gamma=0.1).initialize_object()\n",
    "seed = 6174\n",
    "logger = [WandBLoggerHparams(\"lth_diet\", \"crazy\", entity=\"prunes\").initialize_object()]\n",
    "callback = [LRMonitorHparams().initialize_object()]\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    train_dataloader=train_data, \n",
    "    max_duration=max_duration, \n",
    "    eval_dataloader=test_data,\n",
    "    algorithms=algorithms,\n",
    "    optimizers=optimizer, \n",
    "    schedulers=scheduler,\n",
    "    device=\"gpu\", \n",
    "    # validate_every_n_batches=195, \n",
    "    # validate_every_n_epochs=-1,\n",
    "    precision=\"amp\", \n",
    "    step_schedulers_every_batch=True,\n",
    "    seed=seed, \n",
    "    loggers=logger,\n",
    "    callbacks=callback,\n",
    "    # save_folder=\"/home/mansheej/lth_diet/ipynbs/crazy/ckpts\",\n",
    "    # save_name_format=\"{batch}ba\",\n",
    "    # save_latest_format=None,\n",
    "    # save_interval=\"195ba\",\n",
    "    # save_weights_only=True)\n",
    ")\n",
    "trainer.fit()\n",
    "model.cpu()\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the model trained from the rewind point but with `mask_5` as `model_5__f`. It has  \n",
    "Density = 33%  \n",
    "Test Accuracy = %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model density: 0.32766449451446533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model test accuracy: 0.9156000018119812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"model_5__f\", \"mask_5\", model_hparams)\n",
    "print(\"Model density:\", get_pruned_model_density(model))\n",
    "print(\"Model test accuracy:\", get_accuracy(model, test_data))\n",
    "# save_model(model, \"model_5__f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarkably `model_5__f` and `mmodel_5__1` are indeed ***ERROR CONNECTED***.  \n",
    "Test accuracy `model_5__f` = 91.56%  \n",
    "Test accuracy midpoint = 91.40%  \n",
    "Test accuracy `model_5__1` = 91.73%  \n",
    "Sad, this didn't work as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 10.83it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 10.56it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 10.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of (model_denser, model_midpoint, model_sparser) = (0.9156000018119812, 0.914199948310852, 0.9151999950408936)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Test accuracy of (model_denser, model_midpoint, model_sparser) =\",\n",
    "    compare_to_midpoint(\"model_5__f\", \"mask_5\", \"model_5__1\", \"mask_5\", test_data, get_accuracy, model_hparams)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6ede5693076468011a9b06db16dff54c2e2dab3909e284e06b92eee2c289d4c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('lth_diet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
